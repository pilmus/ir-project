{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from pyserini.index import IndexReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "index_reader = IndexReader(\"../anserini/indexes/msmarco-doc/lucene-index-msmarco\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# The query string for each topicid is querystring[topicid]\n",
    "querystring = {}\n",
    "with gzip.open(\"data/msmarco-doctrain-queries.tsv.gz\", 'rt', encoding='utf8') as f:\n",
    "    tsvreader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for [topicid, querystring_of_topicid] in tsvreader:\n",
    "        querystring[topicid] = querystring_of_topicid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# In the corpus tsv, each docid occurs at offset docoffset[docid]\n",
    "\n",
    "docoffset = {}\n",
    "with gzip.open(\"data/msmarco-docs-lookup.tsv.gz\", 'rt', encoding='utf8') as f:\n",
    "    tsvreader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for [docid, _, offset] in tsvreader:\n",
    "        docoffset[docid] = int(offset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# For each topicid, the list of positive docids is qrel[topicid]\n",
    "qrel = {}\n",
    "with gzip.open(\"data/msmarco-doctrain-qrels.tsv.gz\", 'rt', encoding='utf8') as f:\n",
    "    tsvreader = csv.reader(f, delimiter=\" \")\n",
    "    for [topicid, _, docid, rel] in tsvreader:\n",
    "        assert rel == \"1\"\n",
    "        if topicid in qrel:\n",
    "            qrel[topicid].append(docid)\n",
    "        else:\n",
    "            qrel[topicid] = [docid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# def compute_doc_tf(query, document_id):\n",
    "#     val = 0\n",
    "#     query_terms = index_reader.analyze(query)\n",
    "#     doc_vector = index_reader.get_document_vector(document_id)\n",
    "#\n",
    "#     for term in query_terms:\n",
    "#         tf = doc_vector.get(term,0)\n",
    "#         val += tf\n",
    "#     return val\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# def compute_tf(query, string):\n",
    "#     val = 0\n",
    "#     query_terms = index_reader.analyze(query)\n",
    "#     string_terms = index_reader.analyze(string)\n",
    "#     string_terms_counts = Counter(string_terms)\n",
    "#     for term in query_terms:\n",
    "#         val += string_terms_counts.get(term,0)\n",
    "#     return val\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# with open('data/msmarco-doc-libsvm/msmarco-doctrain-libsv.txt', 'w', newline='') as csvfile:\n",
    "#     csvwriter = csv.writer(csvfile, delimiter=' ')\n",
    "#     for query_id in itertools.islice(querystring, 10):\n",
    "#         query = querystring[query_id]\n",
    "#         rel_doc_ids = qrel[query_id]\n",
    "#         for rel_doc_id in rel_doc_ids:\n",
    "#             doc_tf = compute_doc_tf(query,rel_doc_id)\n",
    "#             doc_len = len(index_reader.doc(rel_doc_id).raw())\n",
    "#             csvwriter.writerow([1,f\"qid:{query_id}\",f\"1:{doc_tf}\", f\"2:{doc_len}\", f\"#DOCID:{rel_doc_id}\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "d = index_reader.doc('D2192591')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bomb.cit': 1,\n 'german': 2,\n 'been': 1,\n 'half': 2,\n 'refus': 2,\n 'govern': 3,\n 'potenti': 2,\n 'year': 4,\n 'japanes': 2,\n 'del': 1,\n 'complet': 1,\n 'via': 1,\n 'nazi': 3,\n 'suffer': 1,\n 'would': 9,\n 'near': 2,\n 'ten': 1,\n 'chicago': 2,\n 'berklei': 1,\n 'despit': 3,\n 'tennesse': 1,\n 'pass': 1,\n 'ag': 2,\n 'mile': 7,\n 'impact': 2,\n 'reluct': 1,\n 'shock': 1,\n 'enthusiast': 1,\n 'am': 1,\n 'headquart': 1,\n 'truman': 3,\n 'codenam': 3,\n 'aioi': 1,\n 'extend': 2,\n 'alamo': 3,\n '2': 2,\n 'befor': 2,\n 'globe': 1,\n 'nagasaki': 3,\n 'size': 1,\n '5': 1,\n 'left': 1,\n '6': 1,\n '7': 1,\n 'plant': 1,\n 'urei': 1,\n 'wwii': 2,\n '8': 3,\n '9': 1,\n 'juli': 1,\n 'much': 1,\n 'be': 2,\n 'fate': 1,\n 'dead': 2,\n 'turn': 1,\n \"we'r\": 1,\n 'dollar': 1,\n 'journal': 1,\n 'same': 1,\n 'releas': 2,\n 'pacifist': 1,\n 'foot': 1,\n 'descend': 1,\n 'mind': 3,\n 'b': 1,\n 'c': 1,\n 'd': 1,\n 'i': 1,\n 'abl': 2,\n 'j': 1,\n 'co': 1,\n 'blast': 2,\n 'survivor': 1,\n 'insid': 1,\n 'r': 1,\n 's': 9,\n '40,000': 1,\n 'u': 10,\n 'y': 1,\n 'somewhat': 1,\n 'goggl': 1,\n 'river': 1,\n 'desert': 2,\n 'imagesbi': 1,\n 'under': 1,\n 'god': 1,\n 'deadli': 1,\n 'thu': 1,\n 'die': 1,\n 'fleet': 1,\n '33rd': 1,\n 'di': 1,\n 'forc': 3,\n 'down': 1,\n 'outlin': 1,\n 'act': 1,\n 'later': 2,\n 'hiroshima': 3,\n 'radioact': 2,\n 'contact': 2,\n 'won': 1,\n 'rel': 1,\n 'serious': 1,\n '69,000': 1,\n 'area': 2,\n 'which': 5,\n 'initi': 1,\n 'signific': 1,\n 'test': 10,\n 'need': 2,\n 'wrote': 2,\n 'Â©': None,\n 'check': 1,\n 'massiv': 1,\n 'emigr': 2,\n 'never': 1,\n 'sand': 1,\n 'she': 1,\n 'month': 1,\n 'isol': 1,\n 'success': 4,\n '6,000': 1,\n 'final': 1,\n 'http': 1,\n 'injur': 4,\n 'octob': 1,\n 'uneas': 1,\n 'einstein': 4,\n 'washington': 1,\n 'hundr': 2,\n 'some': 3,\n 'ascend': 1,\n 'univers': 7,\n 'consequ': 2,\n 'ridg': 2,\n 'pound': 1,\n 'accomplish': 1,\n 'petit': 1,\n 'journei': 1,\n 'rate': 1,\n 'germani': 3,\n 'skill': 1,\n 'oak': 2,\n 'end': 6,\n 'brigadi': 1,\n 'nuclear': 2,\n 'human': 1,\n 'just': 1,\n 'live': 1,\n 'over': 5,\n 'spanish': 1,\n 'brilliant': 1,\n 'berkelei': 1,\n 'pilot': 1,\n 'six': 1,\n 'length': 1,\n 'roosevelt': 4,\n 'anyth': 2,\n 'magnitud': 1,\n 'howev': 2,\n 'magnet': 1,\n 'energi': 2,\n 'gida': 1,\n 'oxid': 1,\n 'special': 1,\n 'argu': 1,\n 'print': 1,\n 'surrend': 5,\n 'wwiigermani': 1,\n 'well': 1,\n 'personnel': 1,\n 'renew': 1,\n 'astonish': 1,\n 'he': 4,\n 'hi': 3,\n 'particl': 1,\n 'gadget': 1,\n 'told': 2,\n 'american': 4,\n 'devot': 1,\n 'construct': 1,\n 'ignor': 1,\n 'sick': 1,\n 'hope': 1,\n 'soon': 1,\n 'number': 1,\n 'veri': 1,\n 'four': 1,\n 'action': 1,\n 'enola': 1,\n 'decemb': 2,\n 'text': 2,\n 'decis': 1,\n 'promin': 1,\n 'bhagavad': 1,\n 'fear': 2,\n 'ii': 1,\n 'sky': 1,\n 'creat': 7,\n 'colleagu': 1,\n 'shape': 1,\n 'director': 3,\n 'made': 1,\n 'understand': 1,\n 'it': 4,\n 'protest': 1,\n 'physicist': 2,\n 'muerto': 1,\n 'surviv': 1,\n 'advisori': 2,\n 'system': 1,\n 'million': 2,\n 'schwartz': 1,\n 'experi': 1,\n 'becam': 3,\n 'singl': 1,\n 'gave': 1,\n 'john': 1,\n 'disintegr': 1,\n 'begin': 1,\n 'don': 1,\n 'other': 3,\n 'upset': 1,\n 'brought': 3,\n 'natur': 1,\n 'against': 2,\n 'costli': 1,\n 'believ': 1,\n 'triniti': 4,\n 'summer': 1,\n 'robert': 2,\n 'world': 6,\n 'known': 4,\n 'mai': 1,\n 'top': 1,\n 'too': 2,\n 'locat': 1,\n 'have': 3,\n 'share': 1,\n 'man': 2,\n 'stand': 1,\n 'surround': 1,\n 'vapor': 1,\n 'break': 2,\n 'within': 2,\n 'could': 3,\n 'discoveri': 1,\n 'knew': 2,\n 'littl': 2,\n 'citi': 2,\n 'exampl': 1,\n 'rose': 1,\n 'atom': 21,\n 'thousand': 2,\n 'inferno': 1,\n 'feet': 2,\n 'leukemia': 1,\n 'lo': 3,\n 'jornada': 1,\n 'anxiou': 1,\n 'sign': 1,\n 'remot': 2,\n 'while': 3,\n 'second': 2,\n 'getti': 1,\n 'high': 2,\n 'son': 1,\n 'split': 1,\n 'than': 1,\n 'commun': 1,\n 'hanford': 1,\n 'tower': 2,\n 'all': 2,\n 'armi': 1,\n 'new': 7,\n 'took': 4,\n 'fermi': 1,\n 'terror': 1,\n 'occur': 1,\n 'difficult': 1,\n 'tri': 1,\n 'less': 1,\n 'my': 1,\n 'absolut': 1,\n 'unit': 4,\n 'famou': 1,\n 'alreadi': 1,\n 'were': 11,\n 'true': 1,\n 'updat': 1,\n 'franklin': 1,\n 'uranium': 7,\n 'produc': 2,\n 'boi': 2,\n 'gear': 1,\n 'heat': 1,\n 'behind': 1,\n 'bridg': 1,\n 'best': 2,\n 'respons': 3,\n 'head': 1,\n 'total': 3,\n 'men': 1,\n 'chose': 1,\n 'involv': 1,\n 'isidor': 1,\n 'possibl': 1,\n 'somehow': 1,\n 'met': 1,\n 'on': 6,\n 'szilard': 2,\n 'brief': 1,\n 'burn': 2,\n 'endeavor': 1,\n 'homeless': 1,\n 'control': 1,\n 'corbi': 2,\n '100': 1,\n 'committe': 3,\n 'dud': 1,\n 'due': 2,\n 'offici': 1,\n 'until': 4,\n 'equilibrium': 1,\n 'oppenheim': 6,\n 'threat': 3,\n 'diffus': 1,\n 'cultur': 1,\n 'thought': 1,\n 'japan': 8,\n 'pu': 1,\n 'millionth': 1,\n 'about': 2,\n 'led': 1,\n 'simultan': 1,\n 'danger': 2,\n 'environ': 1,\n '235': 2,\n 'decad': 1,\n 'leo': 1,\n '239': 2,\n 'let': 1,\n 'state': 4,\n 'eventu': 1,\n 'mushroom': 1,\n 'recent': 1,\n 'immedi': 2,\n 'pearl': 1,\n 'shelli': 1,\n '12': 1,\n 'a.m': 1,\n '13': 1,\n '14': 1,\n 'mankind': 1,\n '15': 1,\n 'august': 4,\n '16': 2,\n 'began': 3,\n 'devast': 1,\n 'gener': 2,\n 'want': 1,\n 'radiat': 3,\n 'realiti': 2,\n 'them': 2,\n '120': 1,\n 'aftermath': 2,\n 'includ': 1,\n 'slow': 2,\n 'destruct': 2,\n 'letter': 1,\n 'declar': 1,\n 'lewi': 1,\n 'overse': 1,\n 'flash': 2,\n 'cyclotron': 1,\n '29': 1,\n 'vigor': 1,\n 'recommend': 1,\n 'graphit': 2,\n 'sun': 1,\n 'two': 5,\n 'populac': 1,\n 'seen': 1,\n 'devis': 1,\n 'moment': 1,\n 'atmospher': 1,\n 'ken': 1,\n 'ernest': 1,\n 'dilig': 1,\n 'taken': 2,\n '1991237': 1,\n 'anoth': 1,\n '30': 1,\n 'email': 1,\n 'vice': 1,\n 'reaction': 6,\n 'poison': 1,\n 'though': 1,\n 'manhattan': 10,\n 'team': 1,\n 'kick': 1,\n 'watch': 1,\n '66,000': 1,\n 'bui': 1,\n 'ask': 1,\n 'progress': 1,\n 'oper': 1,\n 'mani': 2,\n 'thing': 2,\n 'open': 1,\n 'rabi': 1,\n 'project': 12,\n 'express': 1,\n 'had': 7,\n 'bomb': 28,\n 'research': 5,\n 'worri': 1,\n 'zero': 1,\n '2017dure': 1,\n 'countri': 2,\n 'fallout': 1,\n 'loos': 1,\n 'neutron': 1,\n 'sever': 2,\n '1939': 3,\n '1938': 1,\n 'california': 1,\n 'up': 3,\n 'stupend': 1,\n 'jew': 1,\n 'discov': 1,\n 'us': 1,\n 'given': 1,\n 'glass': 1,\n 'lawrenc': 1,\n 'last': 4,\n 'town': 1,\n 'laboratori': 3,\n 'might': 1,\n 'alarmingli': 1,\n 'felt': 1,\n 'develop': 4,\n 'dure': 1,\n 'girl': 1,\n '200,000': 1,\n '1942': 4,\n 'warn': 1,\n '1941': 1,\n 'extract': 1,\n 'name': 5,\n '61': 1,\n 'neighborhood': 1,\n 'support': 2,\n '1945': 8,\n 'sinc': 1,\n 'full': 1,\n 'drop': 5,\n 'next': 1,\n 'blind': 1,\n 'color': 1,\n 'scientist': 9,\n 'concept': 1,\n 'effort': 1,\n 'gai': 1,\n 'wave': 2,\n 'we': 1,\n 'peopl': 7,\n 'scientif': 2,\n 'weapon': 4,\n 'poem': 1,\n 'introduct': 2,\n 'now': 5,\n 'throughout': 2,\n 'gaseou': 1,\n 'wai': 1,\n 'presid': 7,\n 'green': 1,\n 'race': 2,\n 'europ': 1,\n 'hawaii': 1,\n 'refuge': 1,\n 'shore': 1,\n 'war': 8,\n 'technician': 1,\n 'target': 2,\n 'equal': 1,\n 'awai': 3,\n 'knowledg': 1,\n 'what': 3,\n 'refer': 1,\n 'base': 2,\n 'septemb': 1,\n 'yard': 1,\n 'isotop': 1,\n 'arsen': 1,\n 'displac': 1,\n 'realiz': 1,\n 'april': 1,\n 'three': 2,\n 'when': 3,\n 'children': 1,\n '25,000': 1,\n 'far': 1,\n 'lost': 1,\n 'quickli': 1,\n 'fat': 1,\n 'www.thoughtco.com': 1,\n 'enter': 1,\n 'prioriti': 1,\n 'ota': 1,\n 'case': 1,\n 'still': 1,\n 'work': 4,\n 'destroy': 1,\n 'studi': 1,\n 'toward': 1,\n 'columbia': 3,\n 'light': 1,\n 'among': 1,\n 'lesli': 1,\n 'explos': 1,\n 'quot': 1,\n 'engin': 1,\n 'underestim': 1,\n 'bomber': 1,\n 'bright': 1,\n 'terribl': 1,\n 'secret': 4,\n 'out': 1,\n 'across': 1,\n 'caus': 3,\n 'fall': 1,\n 'blaze': 1,\n 'get': 1,\n 'scatter': 1,\n 'place': 2,\n 'power': 1,\n 'event': 1,\n 'chain': 4,\n 'more': 3,\n 'militari': 3,\n 'suggest': 1,\n 'kill': 3,\n 'morn': 1,\n 'rotund': 1,\n 'expect': 1,\n 'help': 1,\n 'mexico': 3,\n 'site': 8,\n 'grove': 2,\n 'nucleu': 1,\n '10,000': 1,\n 'harri': 1,\n 'pacif': 1,\n 'diamet': 1,\n 'bainbridg': 1,\n 'first': 8,\n 'span': 1,\n 'small': 1,\n 'reveal': 1,\n 'harbor': 1,\n 'separ': 1,\n 'dai': 4,\n 'cloud': 1,\n 'enrico': 1,\n 'outlaid': 1,\n 'zone': 1,\n 'enrich': 1,\n 'from': 11,\n 'consider': 1,\n 'rain': 1,\n 'bitch': 1,\n 'donn': 1,\n 'onli': 1,\n 'done': 1,\n 'plutonium': 2,\n 'both': 1,\n 'most': 3,\n 'twice': 1,\n 'warfar': 1,\n 'effect': 2,\n 'fission': 1,\n 'keep': 1,\n 'ground': 2,\n 'histori': 2,\n 'who': 2,\n 'flammabl': 1,\n 'death': 2,\n 'line': 1,\n 'reactor': 1,\n 'continu': 2,\n 'jade': 1,\n 'becom': 3,\n 'everyon': 3,\n 'resid': 1,\n '39,000': 1,\n 'billion': 1,\n 'albert': 1,\n 'inventor': 1,\n 'sai': 2,\n 'said': 1,\n 'process': 1,\n 'cost': 1,\n 'wit': 1,\n 'built': 2,\n 'readi': 1,\n 'clear': 1,\n 'saw': 2,\n 'also': 2,\n 'harold': 1,\n 'flipboard': 1,\n 'fragment': 1,\n 'york': 2,\n 'approv': 1}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_reader.get_document_vector('D2192591')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def lmir_jm(term, doc_vector, sm_param, corpus_prob_term, doc_len):\n",
    "    return (1-sm_param) * doc_vector[term] / doc_len + sm_param * corpus_prob_term\n",
    "\n",
    "def lmir_dirichlet(term, doc_vector, param, corpus_prob_term, doc_len):\n",
    "    return (doc_vector[term] + param * corpus_prob_term) / (doc_len + param)\n",
    "\n",
    "def lmir_abs(term, doc_vector, param, corpus_prob_term, doc_len):\n",
    "   return np.max(doc_vector[term] - param, 0) / doc_len + param * (len(doc_vector) / doc_len) * corpus_prob_term\n",
    "\n",
    "def compute_lmir(query_terms: List[str], index_reader: IndexReader, doc_id: str, smoothing, sm_param=0.1):\n",
    "    doc_vector = index_reader.get_document_vector(doc_id)\n",
    "    doc_len = len(index_reader.doc(doc_id).raw())\n",
    "\n",
    "    doc_vector_not_none_keys = [key for key in doc_vector.keys() if doc_vector[key] is not None]\n",
    "    corpus_frequency_dict = dict.fromkeys(doc_vector_not_none_keys)\n",
    "    lmir_dict = dict.fromkeys(doc_vector_not_none_keys)\n",
    "\n",
    "    total_term_count = index_reader.stats()['total_terms']\n",
    "\n",
    "    if smoothing == 'JM':\n",
    "        lmir = lmir_jm\n",
    "    elif smoothing =='DIR':\n",
    "        lmir = lmir_dirichlet\n",
    "    elif smoothing == \"ABS\":\n",
    "        lmir = lmir_abs\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "    for term in lmir_dict:\n",
    "        corpus_prob_term = index_reader.get_term_counts(term, analyzer=None)[1] / total_term_count\n",
    "        lmir_prob_term = lmir(term, doc_vector, sm_param, corpus_prob_term, doc_len)\n",
    "\n",
    "        corpus_frequency_dict[term] = corpus_prob_term\n",
    "        lmir_dict[term] = lmir_prob_term\n",
    "\n",
    "\n",
    "    alpha_norm = (1 - sum(lmir_dict.values())) / (1 - sum(corpus_frequency_dict.values()))\n",
    "\n",
    "    lmir = 1\n",
    "    for term in query_terms:\n",
    "        if term in lmir_dict:\n",
    "            lmir *= lmir_dict[term]\n",
    "        else:\n",
    "            lmir *= alpha_norm * index_reader.get_term_counts(term, analyzer= None)[1] / total_term_count\n",
    "\n",
    "\n",
    "    return lmir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "q = querystring['1185869']\n",
    "qt = index_reader.analyze(q)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "doc_len = len(index_reader.doc('D59219').raw())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "8.92007884921995e-22"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lmir(qt, index_reader,'D59219', smoothing='JM',sm_param=0.1 / (0.1 + doc_len))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "8.920078849219953e-22"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lmir(qt, index_reader,'D59219', smoothing='DIR', sm_param=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "8.560142081818295e-22"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lmir(qt, index_reader,'D59219', smoothing='ABS', sm_param=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}